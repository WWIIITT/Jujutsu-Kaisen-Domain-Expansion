{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da187df0-a27f-49d2-9db7-ef93f39af222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.11.7)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "Sound file not found. Will continue without sound effects.\n",
      "✅ Jujutsu Kaisen Domain Expansion recognition system initialized\n",
      "\n",
      "== JUJUTSU KAISEN DOMAIN EXPANSION RECOGNITION ==\n",
      "1: Collect Training Data\n",
      "2: Train Model\n",
      "3: Start Recognition\n",
      "4: Exit\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Select an option:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== DATA COLLECTION MODE ==\n",
      "Press keys 1-4 to select a domain to collect data for:\n",
      "1: Infinite Void (Gojo)\n",
      "2: Chimera Shadow (Megumi)\n",
      "3: Idle Transfiguration (Mahito)\n",
      "4: Prison Realm (Geto/Kenjaku)\n",
      "Press 'R' to start/stop recording frames\n",
      "Press 'S' to save the collected data\n",
      "Press 'Q' to quit\n",
      "Selected domain: infinite_void\n",
      "Started recording frames for infinite_void\n",
      "Stopped recording. Collected 1335 frames for infinite_void\n",
      "Started recording frames for infinite_void\n",
      "Stopped recording. Collected 1356 frames for infinite_void\n",
      "Saving 1356 frames as new data\n",
      "✅ Saved 1356 samples for infinite_void\n",
      "No data to save\n",
      "\n",
      "== JUJUTSU KAISEN DOMAIN EXPANSION RECOGNITION ==\n",
      "1: Collect Training Data\n",
      "2: Train Model\n",
      "3: Start Recognition\n",
      "4: Exit\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import pygame\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "\n",
    "class JujutsuKaisenGestureRecognition:\n",
    "    def __init__(self):\n",
    "        # Initialize MediaPipe\n",
    "        self.mp_hands = mp.solutions.hands\n",
    "        self.hands = self.mp_hands.Hands(static_image_mode=False, max_num_hands=2, min_detection_confidence=0.5)\n",
    "        self.mp_drawing = mp.solutions.drawing_utils\n",
    "        \n",
    "        # Domain definitions\n",
    "        self.domain_signs = {\n",
    "            \"infinite_void\": \"無量空處 (Gojo Satoru)\",\n",
    "            \"chimera_shadow\": \"自閉圓頓裡 (Megumi Fushiguro)\",\n",
    "            \"idle_transfiguration\": \"蓋棺鐵處女 (Mahito)\",\n",
    "            \"prison_realm\": \"平安京 (Kenjaku/Geto)\"\n",
    "        }\n",
    "        \n",
    "        # Paths for data storage\n",
    "        self.data_dir = \"jujutsu_data\"\n",
    "        self.model_path = \"jujutsu_model.pkl\"\n",
    "        self.sound_dir = \"sounds\"\n",
    "        self.image_dir = \"images\"\n",
    "        \n",
    "        # Ensure directories exist\n",
    "        for directory in [self.data_dir, self.sound_dir, self.image_dir]:\n",
    "            if not os.path.exists(directory):\n",
    "                os.makedirs(directory)\n",
    "        \n",
    "        # Initialize pygame for sound\n",
    "        pygame.mixer.init()\n",
    "        self.domain_sound = None\n",
    "        try:\n",
    "            self.domain_sound = pygame.mixer.Sound(\"sounds/domain_expansion.wav\")\n",
    "        except:\n",
    "            print(\"Sound file not found. Will continue without sound effects.\")\n",
    "        \n",
    "        # Load or create model\n",
    "        self.model = None\n",
    "        if os.path.exists(self.model_path):\n",
    "            self.load_model()\n",
    "        \n",
    "        # Variables for data collection\n",
    "        self.collecting_data = False\n",
    "        self.current_domain = \"\"\n",
    "        self.collected_frames = []\n",
    "        \n",
    "        # Variables for prediction\n",
    "        self.last_prediction = None\n",
    "        self.prediction_confidence = 0\n",
    "        self.prediction_time = 0\n",
    "        self.cooldown_time = 3  # seconds between predictions\n",
    "        \n",
    "        print(\"✅ Jujutsu Kaisen Domain Expansion recognition system initialized\")\n",
    "\n",
    "    def extract_hand_features(self, image):\n",
    "        \"\"\"Extract hand landmarks from an image\"\"\"\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = self.hands.process(image_rgb)\n",
    "        \n",
    "        # Initialize empty feature vector for 2 hands (21 landmarks per hand, 3 values x,y,z per landmark)\n",
    "        features = np.zeros(126)\n",
    "        \n",
    "        if results.multi_hand_landmarks:\n",
    "            # Process up to 2 hands\n",
    "            for hand_idx, hand_landmarks in enumerate(results.multi_hand_landmarks[:2]):\n",
    "                # Fill in the features for this hand\n",
    "                for i, landmark in enumerate(hand_landmarks.landmark):\n",
    "                    idx = hand_idx * 63 + i * 3\n",
    "                    features[idx] = landmark.x\n",
    "                    features[idx + 1] = landmark.y\n",
    "                    features[idx + 2] = landmark.z\n",
    "                \n",
    "                # Draw landmarks on the image\n",
    "                self.mp_drawing.draw_landmarks(\n",
    "                    image, hand_landmarks, self.mp_hands.HAND_CONNECTIONS)\n",
    "        \n",
    "        return features, image\n",
    "\n",
    "    def collect_data(self):\n",
    "        \"\"\"Run the data collection interface\"\"\"\n",
    "        cv2.namedWindow(\"Jujutsu Kaisen Data Collector\", cv2.WINDOW_NORMAL)\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        \n",
    "        print(\"\\n== DATA COLLECTION MODE ==\")\n",
    "        print(\"Press keys 1-4 to select a domain to collect data for:\")\n",
    "        print(\"1: Infinite Void (Gojo)\")\n",
    "        print(\"2: Chimera Shadow (Megumi)\")\n",
    "        print(\"3: Idle Transfiguration (Mahito)\")\n",
    "        print(\"4: Prison Realm (Geto/Kenjaku)\")\n",
    "        print(\"Press 'R' to start/stop recording frames\")\n",
    "        print(\"Press 'S' to save the collected data\")\n",
    "        print(\"Press 'Q' to quit\")\n",
    "        \n",
    "        domains = list(self.domain_signs.keys())\n",
    "        domain_counts = {domain: 0 for domain in domains}\n",
    "        \n",
    "        # Count existing data\n",
    "        for domain in domains:\n",
    "            domain_path = os.path.join(self.data_dir, f\"{domain}.npy\")\n",
    "            if os.path.exists(domain_path):\n",
    "                existing_data = np.load(domain_path)\n",
    "                domain_counts[domain] = len(existing_data)\n",
    "                print(f\"Found {len(existing_data)} existing samples for {domain}\")\n",
    "        \n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            # Flip the frame for a selfie-view\n",
    "            frame = cv2.flip(frame, 1)\n",
    "            \n",
    "            # Extract hand features\n",
    "            features, processed_frame = self.extract_hand_features(frame)\n",
    "            \n",
    "            # If we're collecting data, store the features\n",
    "            if self.collecting_data:\n",
    "                self.collected_frames.append((features, self.current_domain))\n",
    "                # Display recording indicator\n",
    "                cv2.putText(processed_frame, f\"Recording: {self.current_domain} ({len(self.collected_frames)})\",\n",
    "                            (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "            \n",
    "            # Display instructions and status\n",
    "            cv2.putText(processed_frame, \"1-4: Select Domain, R: Record, S: Save, Q: Quit\",\n",
    "                        (10, frame.shape[0] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "            \n",
    "            # Display current data counts\n",
    "            y_pos = 60\n",
    "            for i, domain in enumerate(domains):\n",
    "                count_text = f\"{i+1}: {domain} - {domain_counts[domain] + (len(self.collected_frames) if self.current_domain == domain and self.collecting_data else 0)}\"\n",
    "                cv2.putText(processed_frame, count_text, (10, y_pos), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "                y_pos += 25\n",
    "            \n",
    "            cv2.imshow(\"Jujutsu Kaisen Data Collector\", processed_frame)\n",
    "            \n",
    "            # Process key presses\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            \n",
    "            if key == ord('q'):\n",
    "                break\n",
    "            elif key == ord('r'):\n",
    "                if self.collecting_data:\n",
    "                    self.collecting_data = False\n",
    "                    print(f\"Stopped recording. Collected {len(self.collected_frames)} frames for {self.current_domain}\")\n",
    "                elif self.current_domain:\n",
    "                    self.collecting_data = True\n",
    "                    print(f\"Started recording frames for {self.current_domain}\")\n",
    "                else:\n",
    "                    print(\"Please select a domain first (press 1-4)\")\n",
    "            elif key == ord('s'):\n",
    "                if self.collected_frames:\n",
    "                    self.save_collected_data()\n",
    "                    # Update counts\n",
    "                    domain_counts[self.current_domain] += len(self.collected_frames)\n",
    "                    self.collected_frames = []\n",
    "                else:\n",
    "                    print(\"No data to save\")\n",
    "            elif key in [ord('1'), ord('2'), ord('3'), ord('4')]:\n",
    "                domain_idx = int(chr(key)) - 1\n",
    "                if domain_idx < len(domains):\n",
    "                    self.current_domain = domains[domain_idx]\n",
    "                    print(f\"Selected domain: {self.current_domain}\")\n",
    "                    if self.collecting_data:\n",
    "                        self.collecting_data = False\n",
    "                        print(\"Recording stopped due to domain change\")\n",
    "        \n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    def save_collected_data(self):\n",
    "        \"\"\"Save the collected frames to disk\"\"\"\n",
    "        if not self.collected_frames:\n",
    "            print(\"No data to save\")\n",
    "            return\n",
    "        \n",
    "        domain_path = os.path.join(self.data_dir, f\"{self.current_domain}.npy\")\n",
    "        \n",
    "        # Extract features and labels\n",
    "        features = np.array([f[0] for f in self.collected_frames])\n",
    "        labels = np.array([f[1] for f in self.collected_frames])\n",
    "        \n",
    "        # Check if we already have data for this domain\n",
    "        if os.path.exists(domain_path):\n",
    "            existing_data = np.load(domain_path)\n",
    "            existing_labels = np.load(domain_path.replace(\".npy\", \"_labels.npy\"))\n",
    "            features = np.vstack((existing_data, features))\n",
    "            labels = np.hstack((existing_labels, labels))\n",
    "            print(f\"Appending {len(self.collected_frames)} frames to existing data\")\n",
    "        else:\n",
    "            print(f\"Saving {len(self.collected_frames)} frames as new data\")\n",
    "        \n",
    "        # Save the data\n",
    "        np.save(domain_path, features)\n",
    "        np.save(domain_path.replace(\".npy\", \"_labels.npy\"), labels)\n",
    "        \n",
    "        print(f\"✅ Saved {len(features)} samples for {self.current_domain}\")\n",
    "        self.collected_frames = []\n",
    "\n",
    "    def train_model(self):\n",
    "        \"\"\"Train the gesture recognition model\"\"\"\n",
    "        print(\"\\n== TRAINING MODEL ==\")\n",
    "        \n",
    "        # Check if we have data\n",
    "        if not os.path.exists(self.data_dir):\n",
    "            print(\"❌ No data directory found\")\n",
    "            return\n",
    "        \n",
    "        # Collect all data\n",
    "        features = []\n",
    "        labels = []\n",
    "        \n",
    "        for domain in self.domain_signs.keys():\n",
    "            domain_path = os.path.join(self.data_dir, f\"{domain}.npy\")\n",
    "            if os.path.exists(domain_path):\n",
    "                domain_features = np.load(domain_path)\n",
    "                domain_labels = np.load(domain_path.replace(\".npy\", \"_labels.npy\"))\n",
    "                \n",
    "                features.append(domain_features)\n",
    "                labels.append(domain_labels)\n",
    "                print(f\"Loaded {len(domain_features)} samples for {domain}\")\n",
    "        \n",
    "        if not features:\n",
    "            print(\"❌ No training data found\")\n",
    "            return\n",
    "        \n",
    "        # Combine all data\n",
    "        X = np.vstack(features)\n",
    "        y = np.hstack(labels)\n",
    "        \n",
    "        print(f\"Total dataset: {len(X)} samples\")\n",
    "        \n",
    "        # Split data into train and test sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        \n",
    "        # Train a RandomForest classifier\n",
    "        print(\"Training RandomForest classifier...\")\n",
    "        self.model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "        self.model.fit(X_train, y_train)\n",
    "        \n",
    "        # Evaluate the model\n",
    "        y_pred = self.model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print(f\"Model accuracy: {accuracy:.2f}\")\n",
    "        \n",
    "        # Save the model\n",
    "        with open(self.model_path, 'wb') as f:\n",
    "            pickle.dump(self.model, f)\n",
    "        \n",
    "        print(f\"✅ Model saved to {self.model_path}\")\n",
    "\n",
    "    def load_model(self):\n",
    "        \"\"\"Load a trained model\"\"\"\n",
    "        try:\n",
    "            with open(self.model_path, 'rb') as f:\n",
    "                self.model = pickle.load(f)\n",
    "            print(f\"✅ Loaded model from {self.model_path}\")\n",
    "        except:\n",
    "            print(f\"❌ Could not load model from {self.model_path}\")\n",
    "\n",
    "    def start_recognition(self):\n",
    "        \"\"\"Start the real-time recognition system\"\"\"\n",
    "        if self.model is None:\n",
    "            print(\"❌ No model loaded. Please train a model first.\")\n",
    "            return\n",
    "        \n",
    "        print(\"\\n== RECOGNITION MODE ==\")\n",
    "        print(\"Performing real-time Domain Expansion recognition\")\n",
    "        print(\"Press 'Q' to quit\")\n",
    "        \n",
    "        cv2.namedWindow(\"Jujutsu Kaisen Domain Recognition\", cv2.WINDOW_NORMAL)\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        \n",
    "        domain_effects = {domain: self.create_domain_effect(domain) for domain in self.domain_signs.keys()}\n",
    "        showing_effect = False\n",
    "        effect_start_time = 0\n",
    "        effect_duration = 3  # seconds\n",
    "        \n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            # Flip the frame for a selfie-view\n",
    "            frame = cv2.flip(frame, 1)\n",
    "            orig_frame = frame.copy()\n",
    "            \n",
    "            # If we're showing an effect, overlay it\n",
    "            current_time = time.time()\n",
    "            if showing_effect and current_time - effect_start_time < effect_duration:\n",
    "                # Continue showing effect\n",
    "                domain = self.last_prediction\n",
    "                effect_frame = domain_effects[domain].copy()\n",
    "                \n",
    "                # Calculate opacity based on time (fade in and out)\n",
    "                elapsed = current_time - effect_start_time\n",
    "                if elapsed < 0.5:  # Fade in\n",
    "                    alpha = elapsed / 0.5\n",
    "                elif elapsed > effect_duration - 0.5:  # Fade out\n",
    "                    alpha = (effect_duration - elapsed) / 0.5\n",
    "                else:\n",
    "                    alpha = 1.0\n",
    "                \n",
    "                # Create a combined frame\n",
    "                h, w = frame.shape[:2]\n",
    "                effect_frame = cv2.resize(effect_frame, (w, h))\n",
    "                \n",
    "                # Overlay with transparency\n",
    "                frame = cv2.addWeighted(frame, 1 - 0.7 * alpha, effect_frame, 0.7 * alpha, 0)\n",
    "                \n",
    "                # Add text\n",
    "                domain_name = self.domain_signs[domain]\n",
    "                cv2.putText(frame, f\"DOMAIN EXPANSION: {domain_name}\", \n",
    "                            (int(w/2)-200, h-50), cv2.FONT_HERSHEY_DUPLEX, \n",
    "                            1.0, (0, 0, 255), 2)\n",
    "            else:\n",
    "                showing_effect = False\n",
    "                \n",
    "                # Extract hand features and make a prediction\n",
    "                features, frame = self.extract_hand_features(frame)\n",
    "                \n",
    "                # Only predict if we have a model and it's been enough time since the last prediction\n",
    "                if current_time - self.prediction_time > self.cooldown_time:\n",
    "                    # Check if any hand is detected\n",
    "                    if np.any(features != 0):\n",
    "                        prediction = self.model.predict([features])[0]\n",
    "                        \n",
    "                        # Get prediction probabilities\n",
    "                        probs = self.model.predict_proba([features])[0]\n",
    "                        confidence = np.max(probs)\n",
    "                        \n",
    "                        # Only consider high confidence predictions\n",
    "                        if confidence > 0.7:\n",
    "                            if prediction != self.last_prediction:\n",
    "                                print(f\"Detected: {prediction} ({confidence:.2f})\")\n",
    "                                self.last_prediction = prediction\n",
    "                                self.prediction_confidence = confidence\n",
    "                                self.prediction_time = current_time\n",
    "                                \n",
    "                                # Trigger effect and sound\n",
    "                                showing_effect = True\n",
    "                                effect_start_time = current_time\n",
    "                                \n",
    "                                # Play sound if available\n",
    "                                if self.domain_sound:\n",
    "                                    self.domain_sound.play()\n",
    "            \n",
    "            # Display instructions\n",
    "            cv2.putText(frame, \"Press 'Q' to quit\", (10, 30), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 1)\n",
    "            \n",
    "            # Show the frame\n",
    "            cv2.imshow(\"Jujutsu Kaisen Domain Recognition\", frame)\n",
    "            \n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            if key == ord('q'):\n",
    "                break\n",
    "        \n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    def create_domain_effect(self, domain):\n",
    "        \"\"\"Create a visual effect for a domain expansion\"\"\"\n",
    "        # Create a basic effect (could be improved with images)\n",
    "        width, height = 640, 480\n",
    "        effect = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "        \n",
    "        if domain == \"infinite_void\":\n",
    "            # Gojo's blue/purple infinity\n",
    "            for i in range(20):\n",
    "                radius = int(i * 15)\n",
    "                color = (138, 43, 226) if i % 2 == 0 else (65, 105, 225)\n",
    "                cv2.circle(effect, (width//2, height//2), radius, color, 5)\n",
    "                \n",
    "        elif domain == \"chimera_shadow\":\n",
    "            # Megumi's shadows\n",
    "            for i in range(height):\n",
    "                for j in range(width):\n",
    "                    if np.random.rand() < 0.1:\n",
    "                        effect[i, j] = (0, 0, np.random.randint(100, 180))\n",
    "            # Add some shadow creature silhouettes\n",
    "            for _ in range(5):\n",
    "                x = np.random.randint(100, width-100)\n",
    "                y = np.random.randint(100, height-100)\n",
    "                size = np.random.randint(30, 70)\n",
    "                cv2.circle(effect, (x, y), size, (0, 0, 0), -1)\n",
    "                cv2.circle(effect, (x-10, y-10), 5, (255, 0, 0), -1)  # Red eye\n",
    "                \n",
    "        elif domain == \"idle_transfiguration\":\n",
    "            # Mahito's body transformation\n",
    "            # Create a flesh-like texture\n",
    "            for i in range(height):\n",
    "                for j in range(width):\n",
    "                    if np.random.rand() < 0.5:\n",
    "                        effect[i, j] = (np.random.randint(120, 200), \n",
    "                                      np.random.randint(100, 150), \n",
    "                                      np.random.randint(130, 170))\n",
    "            # Add \"stitches\"\n",
    "            for _ in range(20):\n",
    "                x1 = np.random.randint(0, width)\n",
    "                y1 = np.random.randint(0, height)\n",
    "                x2 = x1 + np.random.randint(-100, 100)\n",
    "                y2 = y1 + np.random.randint(-100, 100)\n",
    "                cv2.line(effect, (x1, y1), (x2, y2), (0, 0, 0), 2)\n",
    "                \n",
    "        elif domain == \"prison_realm\":\n",
    "            # Geto's cursed spirit manipulation\n",
    "            # Create a dark background with cursed energy\n",
    "            effect.fill(20)  # Dark background\n",
    "            # Add some \"cursed spirits\"\n",
    "            for _ in range(30):\n",
    "                x = np.random.randint(0, width)\n",
    "                y = np.random.randint(0, height)\n",
    "                size = np.random.randint(10, 40)\n",
    "                color = (np.random.randint(100, 200), \n",
    "                       np.random.randint(100, 200), \n",
    "                       np.random.randint(100, 200))\n",
    "                cv2.circle(effect, (x, y), size, color, -1)\n",
    "                cv2.circle(effect, (x, y), size+5, (0, 0, 0), 2)\n",
    "        \n",
    "        return effect\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"Main menu interface\"\"\"\n",
    "        while True:\n",
    "            print(\"\\n== JUJUTSU KAISEN DOMAIN EXPANSION RECOGNITION ==\")\n",
    "            print(\"1: Collect Training Data\")\n",
    "            print(\"2: Train Model\")\n",
    "            print(\"3: Start Recognition\")\n",
    "            print(\"4: Exit\")\n",
    "            \n",
    "            choice = input(\"Select an option: \")\n",
    "            \n",
    "            if choice == '1':\n",
    "                self.collect_data()\n",
    "            elif choice == '2':\n",
    "                self.train_model()\n",
    "            elif choice == '3':\n",
    "                self.start_recognition()\n",
    "            elif choice == '4':\n",
    "                print(\"Exiting...\")\n",
    "                break\n",
    "            else:\n",
    "                print(\"Invalid choice, please try again\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    jjk = JujutsuKaisenGestureRecognition()\n",
    "    jjk.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecca1a3-c106-4a95-921d-bcb25eeede73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
