{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a69ad988-2b32-46dc-9ae3-9add014ad965",
   "metadata": {},
   "source": [
    "Check the Domain Expansion hand sign: https://www.wikihow.com/Domain-Expansion-Hand-Sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0958ded8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "015de4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60751dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f770439",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcf6c05d-625b-420d-9bf5-6597b0fe370d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.9.13)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "✅ Loaded model from jujutsu_model.pkl\n",
      "✅ Jujutsu Kaisen Domain Expansion recognition system initialized\n",
      "\n",
      "== JUJUTSU KAISEN DOMAIN EXPANSION RECOGNITION ==\n",
      "1: Collect Training Data\n",
      "2: Train Model\n",
      "3: Start Recognition\n",
      "4: Exit\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Select an option:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== DATA COLLECTION MODE ==\n",
      "Press keys 1-3 to select a domain to collect data for:\n",
      "1: Infinite Void (Gojo)\n",
      "2: Chimera Shadow (Megumi)\n",
      "3: Malevolent Shrine (Sukuna)\n",
      "Press 'R' to start/stop recording frames (1-second delay to prepare)\n",
      "Press 'S' to save the collected data\n",
      "Press 'Q' to quit\n",
      "Found 3518 existing samples for infinite_void\n",
      "Selected domain: chimera_shadow\n",
      "Started recording frames for chimera_shadow\n",
      "Saving 3538 frames as new data\n",
      "✅ Saved 3538 samples for chimera_shadow\n",
      "Selected domain: malevolent_shrine\n",
      "Started recording frames for malevolent_shrine\n",
      "Saving 4031 frames as new data\n",
      "✅ Saved 4031 samples for malevolent_shrine\n",
      "\n",
      "== JUJUTSU KAISEN DOMAIN EXPANSION RECOGNITION ==\n",
      "1: Collect Training Data\n",
      "2: Train Model\n",
      "3: Start Recognition\n",
      "4: Exit\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Select an option:  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== TRAINING MODEL ==\n",
      "Loaded 3518 samples for infinite_void\n",
      "Loaded 3538 samples for chimera_shadow\n",
      "Loaded 4031 samples for malevolent_shrine\n",
      "Total dataset: 11087 samples\n",
      "Training RandomForest classifier...\n",
      "Model accuracy: 0.9995\n",
      "✅ Model saved to jujutsu_model.pkl\n",
      "\n",
      "== JUJUTSU KAISEN DOMAIN EXPANSION RECOGNITION ==\n",
      "1: Collect Training Data\n",
      "2: Train Model\n",
      "3: Start Recognition\n",
      "4: Exit\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Select an option:  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== RECOGNITION MODE ==\n",
      "Performing real-time Domain Expansion recognition\n",
      "Press 'Q' to quit\n",
      "Loaded domain image for infinite_void\n",
      "Loaded domain image for chimera_shadow\n",
      "Loaded domain image for malevolent_shrine\n",
      "Detected: infinite_void (0.88)\n",
      "Error playing sound: 'JujutsuKaisenGestureRecognition' object has no attribute 'sounds'\n",
      "Detected: malevolent_shrine (0.97)\n",
      "Error playing sound: 'JujutsuKaisenGestureRecognition' object has no attribute 'sounds'\n",
      "Detected: malevolent_shrine (0.82)\n",
      "Error playing sound: 'JujutsuKaisenGestureRecognition' object has no attribute 'sounds'\n",
      "Detected: malevolent_shrine (0.82)\n",
      "Error playing sound: 'JujutsuKaisenGestureRecognition' object has no attribute 'sounds'\n",
      "Detected: malevolent_shrine (0.76)\n",
      "Error playing sound: 'JujutsuKaisenGestureRecognition' object has no attribute 'sounds'\n",
      "Detected: infinite_void (0.77)\n",
      "Error playing sound: 'JujutsuKaisenGestureRecognition' object has no attribute 'sounds'\n",
      "Detected: infinite_void (0.77)\n",
      "Error playing sound: 'JujutsuKaisenGestureRecognition' object has no attribute 'sounds'\n",
      "Detected: infinite_void (0.77)\n",
      "Error playing sound: 'JujutsuKaisenGestureRecognition' object has no attribute 'sounds'\n",
      "Detected: chimera_shadow (0.74)\n",
      "Error playing sound: 'JujutsuKaisenGestureRecognition' object has no attribute 'sounds'\n",
      "Detected: chimera_shadow (0.73)\n",
      "Error playing sound: 'JujutsuKaisenGestureRecognition' object has no attribute 'sounds'\n",
      "Detected: chimera_shadow (0.79)\n",
      "Error playing sound: 'JujutsuKaisenGestureRecognition' object has no attribute 'sounds'\n",
      "Detected: chimera_shadow (0.75)\n",
      "Error playing sound: 'JujutsuKaisenGestureRecognition' object has no attribute 'sounds'\n",
      "Detected: malevolent_shrine (0.70)\n",
      "Error playing sound: 'JujutsuKaisenGestureRecognition' object has no attribute 'sounds'\n",
      "Detected: malevolent_shrine (0.71)\n",
      "Error playing sound: 'JujutsuKaisenGestureRecognition' object has no attribute 'sounds'\n",
      "Detected: malevolent_shrine (0.71)\n",
      "Error playing sound: 'JujutsuKaisenGestureRecognition' object has no attribute 'sounds'\n",
      "Detected: infinite_void (0.71)\n",
      "Error playing sound: 'JujutsuKaisenGestureRecognition' object has no attribute 'sounds'\n",
      "\n",
      "== JUJUTSU KAISEN DOMAIN EXPANSION RECOGNITION ==\n",
      "1: Collect Training Data\n",
      "2: Train Model\n",
      "3: Start Recognition\n",
      "4: Exit\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Select an option:  4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting...\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import pygame\n",
    "import requests\n",
    "import time\n",
    "import threading\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class JujutsuKaisenGestureRecognition:\n",
    "    def __init__(self):\n",
    "        # Initialize MediaPipe Hands\n",
    "        self.mp_hands = mp.solutions.hands\n",
    "        self.hands = self.mp_hands.Hands(\n",
    "            static_image_mode=False,\n",
    "            max_num_hands=2,\n",
    "            min_detection_confidence=0.5,\n",
    "            min_tracking_confidence=0.5\n",
    "        )\n",
    "        self.mp_drawing = mp.solutions.drawing_utils\n",
    "        \n",
    "        # Domain definitions \n",
    "        self.domain_signs = {\n",
    "            \"infinite_void\": \"Infinite Void (Gojo Satoru)\",\n",
    "            \"chimera_shadow\": \"Chimera Shadow (Megumi Fushiguro)\",\n",
    "            \"malevolent_shrine\": \"Malevolent Shrine (Sukuna)\"\n",
    "        }\n",
    "        \n",
    "        # Paths for data storage\n",
    "        self.data_dir = \"jujutsu_data\"\n",
    "        self.model_path = \"jujutsu_model.pkl\"\n",
    "        self.sound_dir = \"sounds\"\n",
    "        self.image_dir = \"images\"\n",
    "        \n",
    "        # Ensure directories exist\n",
    "        for directory in [self.data_dir, self.sound_dir, self.image_dir]:\n",
    "            if not os.path.exists(directory):\n",
    "                os.makedirs(directory)\n",
    "        \n",
    "        # Initialize pygame for sound (if available)\n",
    "        try:\n",
    "            pygame.mixer.init()\n",
    "            self.sounds_available = True\n",
    "        except:\n",
    "            print(\"Sound functionality not available. Continuing without sound effects.\")\n",
    "            self.sounds_available = False\n",
    "        \n",
    "        # Load or create model\n",
    "        self.model = None\n",
    "        if os.path.exists(self.model_path):\n",
    "            self.load_model()\n",
    "        \n",
    "        # Variables for data collection\n",
    "        self.collecting_data = False\n",
    "        self.current_domain = \"\"\n",
    "        self.collected_frames = []\n",
    "        self.recording_countdown = 0\n",
    "        \n",
    "        # Variables for prediction\n",
    "        self.last_prediction = None\n",
    "        self.prediction_confidence = 0\n",
    "        self.prediction_time = 0\n",
    "        self.cooldown_time = 3  # seconds between predictions\n",
    "        \n",
    "        # For prediction smoothing\n",
    "        self.hand_history = []\n",
    "        self.hand_history_size = 5\n",
    "        \n",
    "        print(\"✅ Jujutsu Kaisen Domain Expansion recognition system initialized\")\n",
    "\n",
    "    def extract_hand_features(self, frame):\n",
    "        \"\"\"Extract features from hand landmarks using MediaPipe Hands\"\"\"\n",
    "        # Convert image to RGB for MediaPipe\n",
    "        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Process the image with MediaPipe Hands\n",
    "        results = self.hands.process(image_rgb)\n",
    "        \n",
    "        # Create a fixed-size feature vector (42 features per hand)\n",
    "        features = np.zeros(84)\n",
    "        \n",
    "        hands_detected = False\n",
    "        \n",
    "        if results.multi_hand_landmarks:\n",
    "            hands_detected = True\n",
    "            \n",
    "            # Draw hand landmarks on the frame\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                self.mp_drawing.draw_landmarks(\n",
    "                    frame,\n",
    "                    hand_landmarks,\n",
    "                    self.mp_hands.HAND_CONNECTIONS\n",
    "                )\n",
    "            \n",
    "            # Extract features from up to 2 hands\n",
    "            for hand_idx, hand_landmarks in enumerate(results.multi_hand_landmarks[:2]):\n",
    "                for i, landmark in enumerate(hand_landmarks.landmark):\n",
    "                    # Only store x and y coordinates (ignore z)\n",
    "                    base_idx = hand_idx * 42  # 21 landmarks * 2 values per landmark\n",
    "                    features[base_idx + i*2] = landmark.x\n",
    "                    features[base_idx + i*2 + 1] = landmark.y\n",
    "        \n",
    "        return features, frame, hands_detected\n",
    "\n",
    "    def collect_data(self):\n",
    "        \"\"\"Run the data collection interface\"\"\"\n",
    "        cv2.namedWindow(\"Jujutsu Kaisen Data Collector\", cv2.WINDOW_NORMAL)\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        \n",
    "        # Check if camera opened successfully\n",
    "        if not cap.isOpened():\n",
    "            print(\"Error: Could not open camera. Please check your camera connection.\")\n",
    "            return\n",
    "            \n",
    "        # Set camera properties for better performance\n",
    "        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "        \n",
    "        print(\"\\n== DATA COLLECTION MODE ==\")\n",
    "        print(\"Press keys 1-3 to select a domain to collect data for:\")\n",
    "        print(\"1: Infinite Void (Gojo)\")\n",
    "        print(\"2: Chimera Shadow (Megumi)\")\n",
    "        print(\"3: Malevolent Shrine (Sukuna)\")\n",
    "        print(\"Press 'R' to start/stop recording frames (1-second delay to prepare)\")\n",
    "        print(\"Press 'S' to save the collected data\")\n",
    "        print(\"Press 'Q' to quit\")\n",
    "        \n",
    "        domains = list(self.domain_signs.keys())\n",
    "        domain_counts = {domain: 0 for domain in domains}\n",
    "        \n",
    "        # Count existing data\n",
    "        for domain in domains:\n",
    "            domain_path = os.path.join(self.data_dir, f\"{domain}.npy\")\n",
    "            if os.path.exists(domain_path):\n",
    "                try:\n",
    "                    existing_data = np.load(domain_path)\n",
    "                    domain_counts[domain] = len(existing_data)\n",
    "                    print(f\"Found {len(existing_data)} existing samples for {domain}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading existing data for {domain}: {e}\")\n",
    "        \n",
    "        countdown_start = 0\n",
    "        \n",
    "        while True:\n",
    "            # Read a frame\n",
    "            ret, frame = cap.read()\n",
    "            \n",
    "            # Check if frame was read successfully\n",
    "            if not ret:\n",
    "                print(\"Error: Failed to capture frame from camera\")\n",
    "                # Try to reopen the camera\n",
    "                cap.release()\n",
    "                time.sleep(1)\n",
    "                cap = cv2.VideoCapture(0)\n",
    "                if not cap.isOpened():\n",
    "                    print(\"Error: Could not reopen camera. Exiting data collection.\")\n",
    "                    break\n",
    "                continue\n",
    "            \n",
    "            # Flip the frame for a selfie-view\n",
    "            frame = cv2.flip(frame, 1)\n",
    "            \n",
    "            try:\n",
    "                # Extract hand features\n",
    "                features, processed_frame, hands_detected = self.extract_hand_features(frame)\n",
    "                \n",
    "                # Handle recording countdown\n",
    "                current_time = time.time()\n",
    "                if self.recording_countdown > 0:\n",
    "                    # Show countdown\n",
    "                    remaining = max(0, 1 - (current_time - countdown_start))\n",
    "                    if remaining > 0:\n",
    "                        cv2.putText(processed_frame, f\"Starting in: {remaining:.1f}s\", \n",
    "                                    (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)\n",
    "                    else:\n",
    "                        self.recording_countdown = 0\n",
    "                        self.collecting_data = True\n",
    "                        print(f\"Started recording frames for {self.current_domain}\")\n",
    "                \n",
    "                # If we're collecting data, store the features\n",
    "                if self.collecting_data:\n",
    "                    if hands_detected:\n",
    "                        self.collected_frames.append((features, self.current_domain))\n",
    "                        # Display recording indicator\n",
    "                        cv2.putText(processed_frame, f\"Recording: {self.current_domain} ({len(self.collected_frames)})\",\n",
    "                                    (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "                    else:\n",
    "                        # Warn that hands aren't detected\n",
    "                        cv2.putText(processed_frame, \"No hands detected - not recording\", \n",
    "                                    (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "                \n",
    "                # Display instructions and status\n",
    "                cv2.putText(processed_frame, \"1-3: Select Domain, R: Record, S: Save, Q: Quit\",\n",
    "                            (10, frame.shape[0] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)\n",
    "                \n",
    "                # Display current data counts and selected domain\n",
    "                y_pos = 90\n",
    "                for i, domain in enumerate(domains):\n",
    "                    count_text = f\"{i+1}: {domain} - {domain_counts[domain] + (len(self.collected_frames) if self.current_domain == domain and self.collecting_data else 0)}\"\n",
    "                    color = (0, 255, 0) if domain == self.current_domain else (200, 200, 200)\n",
    "                    cv2.putText(processed_frame, count_text, (10, y_pos), \n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 1)\n",
    "                    y_pos += 30\n",
    "                \n",
    "                # Show if hands are detected\n",
    "                hand_status = \"Hands Detected: Yes\" if hands_detected else \"Hands Detected: No\"\n",
    "                cv2.putText(processed_frame, hand_status, (10, frame.shape[0] - 40), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0) if hands_detected else (0, 0, 255), 1)\n",
    "                \n",
    "                # Show the frame\n",
    "                cv2.imshow(\"Jujutsu Kaisen Data Collector\", processed_frame)\n",
    "            except Exception as e:\n",
    "                print(f\"Error in processing frame: {e}\")\n",
    "                # Show a simpler frame if there's an error\n",
    "                cv2.putText(frame, f\"Processing error: {str(e)[:50]}...\", \n",
    "                            (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "                cv2.imshow(\"Jujutsu Kaisen Data Collector\", frame)\n",
    "            \n",
    "            # Process key presses\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            \n",
    "            if key == ord('q'):\n",
    "                break\n",
    "            elif key == ord('r'):\n",
    "                if self.collecting_data:\n",
    "                    self.collecting_data = False\n",
    "                    print(f\"Stopped recording. Collected {len(self.collected_frames)} frames for {self.current_domain}\")\n",
    "                elif self.current_domain:\n",
    "                    # Start countdown\n",
    "                    self.recording_countdown = 1\n",
    "                    countdown_start = current_time\n",
    "                else:\n",
    "                    print(\"Please select a domain first (press 1-3)\")\n",
    "            elif key == ord('s'):\n",
    "                if self.collected_frames:\n",
    "                    try:\n",
    "                        self.save_collected_data()\n",
    "                        # Update counts\n",
    "                        domain_counts[self.current_domain] += len(self.collected_frames)\n",
    "                        self.collected_frames = []\n",
    "                        self.collecting_data = False\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error saving data: {e}\")\n",
    "                else:\n",
    "                    print(\"No data to save\")\n",
    "            elif key in [ord('1'), ord('2'), ord('3')]:\n",
    "                domain_idx = int(chr(key)) - 1\n",
    "                if domain_idx < len(domains):\n",
    "                    self.current_domain = domains[domain_idx]\n",
    "                    print(f\"Selected domain: {self.current_domain}\")\n",
    "                    if self.collecting_data:\n",
    "                        self.collecting_data = False\n",
    "                        print(\"Recording stopped due to domain change\")\n",
    "        \n",
    "        # Clean up\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    def save_collected_data(self):\n",
    "        \"\"\"Save the collected frames to disk\"\"\"\n",
    "        if not self.collected_frames:\n",
    "            print(\"No data to save\")\n",
    "            return\n",
    "        \n",
    "        domain_path = os.path.join(self.data_dir, f\"{self.current_domain}.npy\")\n",
    "        labels_path = os.path.join(self.data_dir, f\"{self.current_domain}_labels.npy\")\n",
    "        \n",
    "        # Extract features and labels\n",
    "        features = np.array([f[0] for f in self.collected_frames])\n",
    "        labels = np.array([f[1] for f in self.collected_frames])\n",
    "        \n",
    "        # Check if we already have data for this domain\n",
    "        if os.path.exists(domain_path) and os.path.exists(labels_path):\n",
    "            try:\n",
    "                existing_data = np.load(domain_path)\n",
    "                existing_labels = np.load(labels_path)\n",
    "                features = np.vstack((existing_data, features))\n",
    "                labels = np.hstack((existing_labels, labels))\n",
    "                print(f\"Appending {len(self.collected_frames)} frames to existing data\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading existing data: {e}. Creating new data file.\")\n",
    "        else:\n",
    "            print(f\"Saving {len(self.collected_frames)} frames as new data\")\n",
    "        \n",
    "        # Save the data\n",
    "        np.save(domain_path, features)\n",
    "        np.save(labels_path, labels)\n",
    "        \n",
    "        print(f\"✅ Saved {len(features)} samples for {self.current_domain}\")\n",
    "        self.collected_frames = []\n",
    "\n",
    "    def train_model(self):\n",
    "        \"\"\"Train the gesture recognition model\"\"\"\n",
    "        print(\"\\n== TRAINING MODEL ==\")\n",
    "        \n",
    "        # Check if we have data\n",
    "        if not os.path.exists(self.data_dir):\n",
    "            print(\"❌ No data directory found\")\n",
    "            return\n",
    "        \n",
    "        # Collect all data\n",
    "        features = []\n",
    "        labels = []\n",
    "        \n",
    "        for domain in self.domain_signs.keys():\n",
    "            domain_path = os.path.join(self.data_dir, f\"{domain}.npy\")\n",
    "            labels_path = os.path.join(self.data_dir, f\"{domain}_labels.npy\")\n",
    "            \n",
    "            if os.path.exists(domain_path) and os.path.exists(labels_path):\n",
    "                try:\n",
    "                    domain_features = np.load(domain_path)\n",
    "                    domain_labels = np.load(labels_path)\n",
    "                    \n",
    "                    features.append(domain_features)\n",
    "                    labels.append(domain_labels)\n",
    "                    print(f\"Loaded {len(domain_features)} samples for {domain}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading data for {domain}: {e}\")\n",
    "        \n",
    "        if not features:\n",
    "            print(\"❌ No training data found\")\n",
    "            return\n",
    "        \n",
    "        # Combine all data\n",
    "        try:\n",
    "            X = np.vstack(features)\n",
    "            y = np.hstack(labels)\n",
    "            \n",
    "            print(f\"Total dataset: {len(X)} samples\")\n",
    "            \n",
    "            # Split data into train and test sets\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "            \n",
    "            # Train a RandomForest classifier\n",
    "            print(\"Training RandomForest classifier...\")\n",
    "            self.model = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "            self.model.fit(X_train, y_train)\n",
    "            \n",
    "            # Evaluate the model\n",
    "            y_pred = self.model.predict(X_test)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            print(f\"Model accuracy: {accuracy:.4f}\")\n",
    "            \n",
    "            # Save the model\n",
    "            with open(self.model_path, 'wb') as f:\n",
    "                pickle.dump(self.model, f)\n",
    "                \n",
    "            print(f\"✅ Model saved to {self.model_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error training model: {e}\")\n",
    "\n",
    "    def load_model(self):\n",
    "        \"\"\"Load a trained model\"\"\"\n",
    "        try:\n",
    "            with open(self.model_path, 'rb') as f:\n",
    "                self.model = pickle.load(f)\n",
    "            print(f\"✅ Loaded model from {self.model_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Could not load model: {e}\")\n",
    "            self.model = None\n",
    "\n",
    "    def smooth_predictions(self, prediction, confidence):\n",
    "        \"\"\"Smooth predictions over time to reduce jitter\"\"\"\n",
    "        # Add current prediction to history\n",
    "        self.hand_history.append((prediction, confidence))\n",
    "        if len(self.hand_history) > self.hand_history_size:\n",
    "            self.hand_history.pop(0)\n",
    "            \n",
    "        # Count occurrences of each prediction\n",
    "        prediction_counts = {}\n",
    "        total_confidence = {}\n",
    "        \n",
    "        for pred, conf in self.hand_history:\n",
    "            if pred not in prediction_counts:\n",
    "                prediction_counts[pred] = 0\n",
    "                total_confidence[pred] = 0\n",
    "            prediction_counts[pred] += 1\n",
    "            total_confidence[pred] += conf\n",
    "            \n",
    "        # Find the most common prediction\n",
    "        max_count = 0\n",
    "        smoothed_prediction = None\n",
    "        smoothed_confidence = 0\n",
    "        \n",
    "        for pred, count in prediction_counts.items():\n",
    "            if count > max_count:\n",
    "                max_count = count\n",
    "                smoothed_prediction = pred\n",
    "                smoothed_confidence = total_confidence[pred] / count\n",
    "                \n",
    "        # Return the smoothed prediction if it's stable enough\n",
    "        if max_count >= 0.6 * len(self.hand_history):\n",
    "            return smoothed_prediction, smoothed_confidence\n",
    "        else:\n",
    "            return None, 0\n",
    "\n",
    "    def start_recognition(self):\n",
    "        \"\"\"Start the real-time recognition system\"\"\"\n",
    "        if self.model is None:\n",
    "            print(\"❌ No model loaded. Please train a model first.\")\n",
    "            return\n",
    "        \n",
    "        print(\"\\n== RECOGNITION MODE ==\")\n",
    "        print(\"Performing real-time Domain Expansion recognition\")\n",
    "        print(\"Press 'Q' to quit\")\n",
    "        \n",
    "        cv2.namedWindow(\"Jujutsu Kaisen Domain Recognition\", cv2.WINDOW_NORMAL)\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        \n",
    "        # Check if camera opened successfully\n",
    "        if not cap.isOpened():\n",
    "            print(\"Error: Could not open camera. Please check your camera connection.\")\n",
    "            return\n",
    "            \n",
    "        # Set camera properties for better performance\n",
    "        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "        \n",
    "        # Initialize hand history for smooth predictions\n",
    "        self.hand_history = []\n",
    "        \n",
    "        showing_effect = False\n",
    "        effect_start_time = 0\n",
    "        effect_duration = 5  # seconds\n",
    "        \n",
    "        # Prepare domain expansion images\n",
    "        domain_images = {}\n",
    "        for domain in self.domain_signs.keys():\n",
    "            img_path = os.path.join(self.image_dir, f\"{domain}.jpg\")\n",
    "            if os.path.exists(img_path):\n",
    "                try:\n",
    "                    domain_images[domain] = cv2.imread(img_path)\n",
    "                    print(f\"Loaded domain image for {domain}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading image for {domain}: {e}\")\n",
    "                    # Create a basic colored background as fallback\n",
    "                    if domain == \"infinite_void\":\n",
    "                        # Blue background for Gojo\n",
    "                        domain_images[domain] = np.ones((480, 640, 3), dtype=np.uint8) * np.array([128, 0, 0], dtype=np.uint8)\n",
    "                    elif domain == \"chimera_shadow\":\n",
    "                        # Dark background for Megumi\n",
    "                        domain_images[domain] = np.ones((480, 640, 3), dtype=np.uint8) * np.array([0, 0, 0], dtype=np.uint8)\n",
    "                    elif domain == \"malevolent_shrine\":\n",
    "                        # Red background for Sukuna\n",
    "                        domain_images[domain] = np.ones((480, 640, 3), dtype=np.uint8) * np.array([0, 0, 128], dtype=np.uint8)\n",
    "            else:\n",
    "                print(f\"No image found for {domain}, creating basic background\")\n",
    "                # Create a basic colored background\n",
    "                if domain == \"infinite_void\":\n",
    "                    # Blue background for Gojo\n",
    "                    domain_images[domain] = np.ones((480, 640, 3), dtype=np.uint8) * np.array([128, 0, 0], dtype=np.uint8)\n",
    "                elif domain == \"chimera_shadow\":\n",
    "                    # Dark background for Megumi\n",
    "                    domain_images[domain] = np.ones((480, 640, 3), dtype=np.uint8) * np.array([0, 0, 0], dtype=np.uint8)\n",
    "                elif domain == \"malevolent_shrine\":\n",
    "                    # Red background for Sukuna\n",
    "                    domain_images[domain] = np.ones((480, 640, 3), dtype=np.uint8) * np.array([0, 0, 128], dtype=np.uint8)\n",
    "        \n",
    "        while True:\n",
    "            # Read a frame\n",
    "            ret, frame = cap.read()\n",
    "            \n",
    "            # Check if frame was read successfully\n",
    "            if not ret:\n",
    "                print(\"Error: Failed to capture frame from camera\")\n",
    "                # Try to reopen the camera\n",
    "                cap.release()\n",
    "                time.sleep(1)\n",
    "                cap = cv2.VideoCapture(0)\n",
    "                if not cap.isOpened():\n",
    "                    print(\"Error: Could not reopen camera. Exiting recognition.\")\n",
    "                    break\n",
    "                continue\n",
    "            \n",
    "            # Flip the frame for a selfie-view\n",
    "            frame = cv2.flip(frame, 1)\n",
    "            \n",
    "            try:\n",
    "                # If we're showing an effect, overlay it\n",
    "                current_time = time.time()\n",
    "                if showing_effect and current_time - effect_start_time < effect_duration:\n",
    "                    # Continue showing effect\n",
    "                    domain = self.last_prediction\n",
    "                    \n",
    "                    # Use the domain image if available\n",
    "                    if domain in domain_images and domain_images[domain] is not None:\n",
    "                        effect_frame = domain_images[domain].copy()\n",
    "                        \n",
    "                        # Calculate opacity based on time (fade in and out)\n",
    "                        elapsed = current_time - effect_start_time\n",
    "                        if elapsed < 0.8:  # Fade in\n",
    "                            alpha = elapsed / 0.8\n",
    "                        elif elapsed > effect_duration - 0.8:  # Fade out\n",
    "                            alpha = (effect_duration - elapsed) / 0.8\n",
    "                        else:\n",
    "                            alpha = 1.0\n",
    "                        \n",
    "                        # Create a combined frame\n",
    "                        h, w = frame.shape[:2]\n",
    "                        effect_frame = cv2.resize(effect_frame, (w, h))\n",
    "                        \n",
    "                        # Overlay with transparency\n",
    "                        frame = cv2.addWeighted(frame, 1 - 0.85 * alpha, effect_frame, 0.85 * alpha, 0)\n",
    "                        \n",
    "                        # Add announcement text\n",
    "                        domain_name = self.domain_signs[domain]\n",
    "                        # Add a dark background for text readability\n",
    "                        text_bg = np.zeros_like(frame)\n",
    "                        cv2.rectangle(text_bg, (0, h-70), (w, h), (0, 0, 0), -1)\n",
    "                        frame = cv2.addWeighted(frame, 1, text_bg, 0.7, 0)\n",
    "                        \n",
    "                        # Add domain expansion text\n",
    "                        cv2.putText(frame, \"DOMAIN EXPANSION\", \n",
    "                                    (int(w/2)-220, h-40), cv2.FONT_HERSHEY_DUPLEX, \n",
    "                                    1.5, (0, 0, 255), 3)\n",
    "                        \n",
    "                        # Add domain name\n",
    "                        cv2.putText(frame, domain_name, \n",
    "                                    (int(w/2)-200, h-10), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                                    0.8, (0, 255, 255), 2)\n",
    "                else:\n",
    "                    showing_effect = False\n",
    "                    \n",
    "                    # Extract hand features and make a prediction\n",
    "                    features, frame, hands_detected = self.extract_hand_features(frame)\n",
    "                    \n",
    "                    # Only predict if we have a model and hands are detected\n",
    "                    if hands_detected and current_time - self.prediction_time > self.cooldown_time:\n",
    "                        # Make prediction\n",
    "                        prediction = self.model.predict([features])[0]\n",
    "                        \n",
    "                        # Get prediction probabilities\n",
    "                        probs = self.model.predict_proba([features])[0]\n",
    "                        confidence = np.max(probs)\n",
    "                        \n",
    "                        # Apply smoothing\n",
    "                        smooth_prediction, smooth_confidence = self.smooth_predictions(prediction, confidence)\n",
    "                        \n",
    "                        # Only consider high confidence predictions\n",
    "                        if smooth_prediction and smooth_confidence > 0.7:\n",
    "                            print(f\"Detected: {smooth_prediction} ({smooth_confidence:.2f})\")\n",
    "                            self.last_prediction = smooth_prediction\n",
    "                            self.prediction_confidence = smooth_confidence\n",
    "                            self.prediction_time = current_time\n",
    "                            \n",
    "                            # Trigger effect and sound\n",
    "                            showing_effect = True\n",
    "                            effect_start_time = current_time\n",
    "                            \n",
    "                            # Play sound if available\n",
    "                            if self.sounds_available:\n",
    "                                try:\n",
    "                                    if \"announcement\" in self.sounds:\n",
    "                                        self.sounds[\"announcement\"].play()\n",
    "                                except Exception as e:\n",
    "                                    print(f\"Error playing sound: {e}\")\n",
    "                    \n",
    "                    # Show hand detection status and confidence\n",
    "                    if hands_detected:\n",
    "                        cv2.putText(frame, \"Hands Detected\", (10, 30), \n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "                        \n",
    "                        # If we've made a recent prediction, show it\n",
    "                        if current_time - self.prediction_time < 10:\n",
    "                            confidence_text = f\"Last: {self.last_prediction} ({self.prediction_confidence:.2f})\"\n",
    "                            cv2.putText(frame, confidence_text, (10, 60), \n",
    "                                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)\n",
    "                    else:\n",
    "                        cv2.putText(frame, \"No Hands Detected\", (10, 30), \n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "                \n",
    "                # Display instructions\n",
    "                cv2.putText(frame, \"Press 'Q' to quit\", (10, frame.shape[0] - 10), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)\n",
    "                \n",
    "                # Show the frame\n",
    "                cv2.imshow(\"Jujutsu Kaisen Domain Recognition\", frame)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing frame: {e}\")\n",
    "                # Create a basic error frame\n",
    "                error_frame = np.ones((480, 640, 3), dtype=np.uint8) * 127  # Gray background\n",
    "                cv2.putText(error_frame, f\"Error: {str(e)[:50]}...\", (50, 240), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "                cv2.putText(error_frame, \"Press 'Q' to quit\", (50, 270), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "                cv2.imshow(\"Jujutsu Kaisen Domain Recognition\", error_frame)\n",
    "            \n",
    "            # Process key presses\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            if key == ord('q'):\n",
    "                break\n",
    "        \n",
    "        # Clean up\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"Main menu interface\"\"\"\n",
    "        while True:\n",
    "            print(\"\\n== JUJUTSU KAISEN DOMAIN EXPANSION RECOGNITION ==\")\n",
    "            print(\"1: Collect Training Data\")\n",
    "            print(\"2: Train Model\")\n",
    "            print(\"3: Start Recognition\")\n",
    "            print(\"4: Exit\")\n",
    "            \n",
    "            try:\n",
    "                choice = input(\"Select an option: \")\n",
    "                \n",
    "                if choice == '1':\n",
    "                    self.collect_data()\n",
    "                elif choice == '2':\n",
    "                    self.train_model()\n",
    "                elif choice == '3':\n",
    "                    self.start_recognition()\n",
    "                elif choice == '4':\n",
    "                    print(\"Exiting...\")\n",
    "                    break\n",
    "                else:\n",
    "                    print(\"Invalid choice, please try again\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error: {e}\")\n",
    "                print(\"Continuing to main menu...\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        jjk = JujutsuKaisenGestureRecognition()\n",
    "        jjk.run()\n",
    "    except Exception as e:\n",
    "        print(f\"Fatal error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecca1a3-c106-4a95-921d-bcb25eeede73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
